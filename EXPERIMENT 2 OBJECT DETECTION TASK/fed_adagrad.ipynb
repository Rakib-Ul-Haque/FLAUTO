{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc64aa6-aaf9-4301-9182-0584e484d543",
   "metadata": {},
   "source": [
    "<h4> This code is part of FLAUTO. It implements FedAdagrad. Date: 01/09/2025 </h4>\n",
    "<h4> Contact: rakibul.haque@utsa.edu </h4>  \n",
    "<h4> Cite as: R. U. Haque and P. Markopoulos,\"Federated Learning with Automated Dual-Level Hyperparameter Tuning\", 2025 <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8977f2-2b93-4cb7-8ed2-c40bb76b2132",
   "metadata": {},
   "source": [
    "<h1><b>Libraries</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f2595-e9ae-445a-8ee6-9087897e42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c00be3-0979-40e1-a120-989b8a3c643e",
   "metadata": {},
   "source": [
    "<h1><b>Measures</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58712144-4c00-46f1-88ae-ab81fcf00366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print function\n",
    "def Print(string, dictionary):\n",
    "    first_key = next(iter(dictionary))\n",
    "    first_value = dictionary[first_key]\n",
    "    print(f\"{string}:{first_key}: {first_value[0][0]}\\n\")\n",
    "\n",
    "# deleting run folder for saving spaces\n",
    "def delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove the folder and all its contents\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' deleted successfully!\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fffbb0-f75b-4dbf-8e1f-c703b691c580",
   "metadata": {},
   "source": [
    "<h1><b>Train function</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104124b5-2d19-42ed-8225-6f7189e29709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_updates(w, n_k):\n",
    "    w_avg = deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        w_avg[key] = torch.mul(w_avg[key], n_k[0])\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] = torch.add(w_avg[key], w[i][key], alpha=n_k[i])\n",
    "        w_avg[key] = torch.div(w_avg[key], sum(n_k))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074839c2-96f9-49cb-acc3-e9804ec0ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(i_w, E, r, c):\n",
    "    global learning_rate, epochs\n",
    "    # Initialize the local model\n",
    "    local_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "    local_model.load_state_dict(i_w)\n",
    "\n",
    "    # Perform local training\n",
    "    local_model.train(data=f\"{fl_a}/{set_up}/c{c}.yaml\", \n",
    "                      project=f\"{dst_folder}/train/round_{r}_client_{c}\", \n",
    "                      workers=0, \n",
    "                      epochs=epochs,  # Ensure epochs is an integer\n",
    "                      imgsz=512, \n",
    "                      lr0=learning_rate,  # Ensure learning_rate is float\n",
    "                      split='train',\n",
    "                      batch=4, \n",
    "                      optimizer=opti,  # Ensure optimizer is correctly specified\n",
    "                      val=True, device=0, warmup_epochs=0)\n",
    "\n",
    "    # Collect final weights\n",
    "    client_final_weights = {k: v.clone().float().to(device) for k, v in local_model.state_dict().items()}\n",
    "    \n",
    "    model_update = {}\n",
    "    for key in local_model.state_dict():\n",
    "        model_update[key] = torch.sub(i_w[key], client_final_weights[key])\n",
    "    \n",
    "    return model_update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98143e70-435d-4eca-a098-baca44aa5a15",
   "metadata": {},
   "source": [
    "<h1><b>FL structure</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e018ca-9d24-401c-83fc-03e9cb1ec4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(i_w, C, P, R, E, b_size, lr=0.001, tau=1e-3):\n",
    "    global global_model\n",
    "    global_model.load_state_dict(i_w)\n",
    "    G = None\n",
    "\n",
    "    for r in range(1, R + 1):\n",
    "        delta = []\n",
    "\n",
    "        # Create a copy of the current global model's weights\n",
    "        #G = {k: v.clone().float() for k, v in global_model.state_dict().items()}\n",
    "        i_w = {k: v.clone().float() for k, v in global_model.state_dict().items()}\n",
    "        Print(\"Model's initial weights:\", {k: v.float() for k, v in i_w.items()})\n",
    "\n",
    "        # Loop for selected clients\n",
    "        for c in range(1, C + 1):\n",
    "            # Training on the client\n",
    "            clients_delta = training(i_w, E, r, c)\n",
    "            delta.append(clients_delta)\n",
    "\n",
    "        # Average the gradients from clients\n",
    "        # average_gradients = average_function(delta)\n",
    "        # update_avg = average_updates(all_clients_updates, data_size)\n",
    "        average_gradients = average_updates(delta, data_size)  #average_function(delta)\n",
    "        \n",
    "        Print(\"Weights difference:\", average_gradients)\n",
    "\n",
    "        if G is None:\n",
    "            G = {key: torch.zeros_like(param).float() for key, param in average_gradients.items()}\n",
    "            \n",
    "        for key in i_w:\n",
    "            # Accumulate the sum of squares of gradients\n",
    "            G[key] += average_gradients[key] ** 2\n",
    "\n",
    "            # Update weights using Adagrad rule\n",
    "            i_w[key] = i_w[key] - ( lr * average_gradients[key] / (torch.sqrt(G[key]) + tau))\n",
    "\n",
    "        \n",
    "        global_model.load_state_dict(i_w)\n",
    "\n",
    "        updated_weights = {k: v.clone().float() for k, v in global_model.state_dict().items()}\n",
    "        Print(f\"Updated global model after round {r}:\", {k: v.float() for k, v in updated_weights.items()})\n",
    "\n",
    "        # Save the updated weights\n",
    "        os.makedirs(os.path.join(dst_folder, \"weights\"), exist_ok=True)\n",
    "        torch.save(global_model, f'{dst_folder}/weights/after_round_{r}_weights.pt')\n",
    "\n",
    "        val_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "        val_model.load_state_dict(updated_weights)\n",
    "        # Perform validation\n",
    "        validation_results = val_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_{r}\", imgsz=512, batch=4, split='val', workers=0, device=0)\n",
    "        validation_dict[f\"round_{r}\"] = validation_results\n",
    "\n",
    "        print(\"Round\", r, \"completed\")\n",
    "        clear_output(wait=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfa716-9624-4848-945f-40ab1f830280",
   "metadata": {},
   "source": [
    "<h1><b>Define Parameters</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582dd5f0-c9cc-4d2c-a75f-310dcfaae587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Parameters==============================================================\n",
    "round_no=30\n",
    "client_no=4\n",
    "participating_client=client_no\n",
    "learning_rate=0.01\n",
    "batch_size=4\n",
    "epochs=5\n",
    "opti='SGD'\n",
    "# momentum=0.937\n",
    "# weight_decay=0.0005\n",
    "data_size=[]\n",
    "\n",
    "#===========other variables=============================================\n",
    "validation_dict = {}\n",
    "\n",
    "fl_a=\"hFL\"\n",
    "set_up=\"IID\"\n",
    "\n",
    "if set_up==\"IID\":\n",
    "    data_size.append(120)\n",
    "    data_size.append(120)\n",
    "    data_size.append(120)\n",
    "    data_size.append(120)\n",
    "else:\n",
    "    data_size.append(120)\n",
    "    data_size.append(120)\n",
    "    data_size.append(120)\n",
    "    data_size.append(43)\n",
    "    \n",
    "\n",
    "forname=set_up\n",
    "\n",
    "dst_folder = f\"{fl_a}_{forname}_Fed_adagrad_{learning_rate}_{opti}\"\n",
    "delete_folder(dst_folder)\n",
    "\n",
    "#===================================loading the saved weight list====================================================\n",
    "global_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "global_model.info()\n",
    "initial_weights = {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "print(len(initial_weights))\n",
    "Print(\"Model's initial weights\", initial_weights)\n",
    "# global_model.save('current.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6150f-c6eb-494f-bd54-4ae1ccf8c41c",
   "metadata": {},
   "source": [
    "<h1><b>Round 0</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049863b-839d-4047-9e14-bf8529af5f1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "#server validation rounds\n",
    "validation_results = l_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_0\", imgsz=512, batch=4,split='val', workers=0,device=0)\n",
    "validation_dict[\"round_0\"] = validation_results\n",
    "print(validation_results)\n",
    "\n",
    "#=================================================================client_1====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c1.yaml\", project=f\"{dst_folder}/train/round_0_client_1\", imgsz=512, batch=4, split='train',  workers=0,device=0)\n",
    "\n",
    "#=================================================================client_2====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c2.yaml\", project=f\"{dst_folder}/train/round_0_client_2\", imgsz=512, batch=4, split='train',  workers=0,device=0)\n",
    "\n",
    "\n",
    "#=================================================================client_3====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c3.yaml\", project=f\"{dst_folder}/train/round_0_client_3\", imgsz=512, batch=4, split='train',  workers=0,device=0)\n",
    "\n",
    "\n",
    "#=================================================================client_4====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c4.yaml\", project=f\"{dst_folder}/train/round_0_client_4\", imgsz=512, batch=4, split='train',  workers=0,device=0)\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abacd373-fecb-4c0e-a112-a37c649ac492",
   "metadata": {},
   "source": [
    "<h1><b>Run FL</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a04c08-997f-4641-afc9-553610909c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parameters 3,085,440 parameters, 3,085,424 gradients\n",
    "federated_learning(initial_weights, client_no, participating_client, round_no, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c2b62e-a250-4440-8d15-6cefba754764",
   "metadata": {},
   "source": [
    "<h1><b>Save the validation dict</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ce2c8-04cd-4e64-9caf-a4c517059d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dict to a serializable format\n",
    "def dict_to_serializable(d):\n",
    "    serializable_dict = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, (int, float, str, list, dict)):\n",
    "            serializable_dict[key] = value\n",
    "        else:\n",
    "            serializable_dict[key] = str(value)  # Convert non-serializable types to string\n",
    "    return serializable_dict\n",
    "\n",
    "# Save as JSON\n",
    "save_dir = dst_folder\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "file_path = os.path.join(save_dir, 'validation_dict.json')\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(dict_to_serializable(validation_dict), f, indent=4)\n",
    "\n",
    "print(f\"Validation dictionary saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65acbf50-7cb6-4f0b-af1f-c42481d74da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(save_dir, 'validation_dict.json')\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, 'r') as f:\n",
    "    loaded_dict = json.load(f)\n",
    "\n",
    "# Print the loaded dictionary\n",
    "print(\"Validation dictionary loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977dbd8-7418-46e7-bfbb-d8101624331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dict['round_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bcff07-cf3a-4c76-bb74-272da69b67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dict['round_30']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
