{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339ff990-e94a-42da-8a36-53e13d603b2f",
   "metadata": {},
   "source": [
    "<h4> This code is part of FLAUTO. It implements FedRFA. Date: 01/09/2025 </h4>\n",
    "<h4> Contact: rakibul.haque@utsa.edu </h4>  \n",
    "<h4> Cite as: R. U. Haque and P. Markopoulos,\"Federated Learning with Automated Dual-Level Hyperparameter Tuning\", 2025 <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a525ad3-a3a2-433e-b8fb-6de546b7069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import copy\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# print function\n",
    "def Print(string, dictionary):\n",
    "    first_key = next(iter(dictionary))\n",
    "    first_value = dictionary[first_key]\n",
    "    print(f\"{string}:{first_key}: {first_value[0][0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df4c21-82c2-4ab3-bc34-f4f85352c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove the folder and all its contents\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' deleted successfully!\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")\n",
    "\n",
    "def smoothed_weiszfeld(models_dict, weights_alpha, initial_weights_dict, nu=1e-5, R_weiszfeld=10):\n",
    "    global device\n",
    "    \n",
    "    # Ensure all tensors are on the same device and of float type\n",
    "    v = {k: v.clone().detach().to(device).float() for k, v in initial_weights_dict.items()}\n",
    "    \n",
    "    for _ in range(int(R_weiszfeld)):\n",
    "        # Compute distances between the current aggregated weights and each model's weights\n",
    "        distances = []\n",
    "        for model in models_dict:\n",
    "            # Move model weights to the same device as v and ensure they are of float type\n",
    "            model = {k: m.to(device).float() for k, m in model.items()}\n",
    "            distance = sum(\n",
    "                torch.norm(v[k] - model[k]).item()  # Convert to Python number for easy use\n",
    "                for k in v.keys()\n",
    "            )\n",
    "            distances.append(distance)\n",
    "        \n",
    "        distances = torch.tensor(distances, device=device).float()\n",
    "        \n",
    "        print(len(weights_alpha), len(distances))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        beta = torch.tensor([alpha_i / max(nu, dist) for alpha_i, dist in zip(weights_alpha, distances)], device=device).float()\n",
    "        \n",
    "        # Compute weighted sum\n",
    "        weighted_sum = {k: torch.zeros_like(v[k], device=device).float() for k in v.keys()}\n",
    "        for beta_i, model in zip(beta, models_dict):\n",
    "            model = {k: m.to(device).float() for k, m in model.items()}  # Ensure model weights are on the same device and of float type\n",
    "            for k in weighted_sum.keys():\n",
    "                weighted_sum[k] += beta_i * model[k]\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_beta = torch.sum(beta)\n",
    "        for k in weighted_sum.keys():\n",
    "            weighted_sum[k] /= total_beta\n",
    "        \n",
    "        # Update v with the new aggregated weights\n",
    "        v = weighted_sum\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba2c95-ab5b-4520-acb1-7258e1792faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training( i_w, E, r, c, learning_rate):\n",
    "    #declear local model\n",
    "    local_model=YOLO(\"initial_weights.pt\").to(device)\n",
    "    local_model.load_state_dict(i_w)\n",
    "    print(local_model.info())\n",
    "    #local_model.load_state_dict(i_w,strict=False)\n",
    "    checking_weights = local_model.state_dict()\n",
    "    Print(f\"Client {c} functions weights\", checking_weights)\n",
    "    \n",
    "    local_model.train(data=f\"{fl_a}/{set_up}/c{c}.yaml\", project=f\"{dst_folder}/train/round_{r}_client_{c}\", workers=0, epochs=E, imgsz=512, lr0=learning_rate, batch=4, optimizer=opti, val=True, device=0, warmup_epochs=0)\n",
    "\n",
    "    #checking initial weights\n",
    "    Print(f\"Client {c} initial weights\", i_w)\n",
    "    #colleting final weights\n",
    "    client_final_weights = {k: v.clone() for k, v in local_model.state_dict().items()}#local_model.state_dict()\n",
    "    Print(f\"Client {c} final weights\",client_final_weights)    \n",
    "    #clear_output(wait=False)\n",
    "    return client_final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0d1c0-4f47-4424-bca6-110470315695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(i_w, C, P, R, E, learning_rate, b_size):\n",
    "    global global_model\n",
    "    global validation_dict\n",
    "    global dst_folder\n",
    "    global device\n",
    "    global_model.load_state_dict(i_w)\n",
    "    \n",
    "    for r in range(1,R+1):\n",
    "        models=[]\n",
    "        weights_alpha = []\n",
    "        i_w = {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "        Print(\"Model's initial weights\", i_w)\n",
    "        #loop for clients\n",
    "        for c in range(1,C+1):\n",
    "            #training\n",
    "            clients_weight=training(i_w, E, r, c, learning_rate)\n",
    "            models.append(clients_weight)\n",
    "            weights_alpha.append(1.0)\n",
    "            \n",
    "        average_weights = smoothed_weiszfeld(models, weights_alpha, i_w)\n",
    "        os.makedirs(os.path.join(dst_folder, \"weights\"), exist_ok=True)  # Creates both Fed_Avg and weights if needed\n",
    "        # Now you can save the weights as usual:\n",
    "        torch.save(average_weights, f'{dst_folder}/weights/after_round_{r}_weighs.pt')\n",
    "\n",
    "        global_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "        global_model.load_state_dict(average_weights)\n",
    "        val_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "        val_model.load_state_dict(average_weights)\n",
    "        #chceking averaged weights\n",
    "        c_weight= {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "        Print(f\"updated global model after round {r}\",c_weight)\n",
    "        \n",
    "        #performing round validations\n",
    "        validation_results = val_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_{r}\", imgsz=512, batch=4, split='val',workers=0)\n",
    "        #save validation results into dict \n",
    "        validation_dict[f\"round_{r}\"] = validation_results\n",
    "        \n",
    "        print(\"round\", r, \"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9076545-94e1-4e45-82aa-ffdad799d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Parameters==============================================================\n",
    "round_no=30\n",
    "client_no=4\n",
    "participating_client=client_no\n",
    "learning_rate=0.01\n",
    "batch_size=4\n",
    "epochs=5\n",
    "opti='SGD'\n",
    "\n",
    "#===========other variables=============================================\n",
    "validation_dict = {}\n",
    "\n",
    "# ===========================================FL type\n",
    "# fl_a=\"vFL\"\n",
    "fl_a=\"hFL\"\n",
    "set_up=\"limited_data\"\n",
    "forname=set_up\n",
    "\n",
    "dst_folder = f\"{fl_a}_{forname}_Fed_RFA_{learning_rate}_{opti}\"\n",
    "delete_folder(dst_folder)\n",
    "\n",
    "#===================================loading the saved weight list====================================================\n",
    "global_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "global_model.info()\n",
    "initial_weights = {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "print(len(initial_weights))\n",
    "Print(\"Model's initial weights\", initial_weights)\n",
    "# global_model.save('current.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb3458-473e-4a00-8779-b1bdc6935243",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "#server validation rounds\n",
    "validation_results = l_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_0\", imgsz=512, batch=4,split='val')\n",
    "validation_dict[\"round_0\"] = validation_results\n",
    "print(validation_results)\n",
    "\n",
    "#=================================================================client_1====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c1.yaml\", project=f\"{dst_folder}/train/round_0_client_1\", imgsz=512, batch=4, split='train')\n",
    "\n",
    "#=================================================================client_2====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c2.yaml\", project=f\"{dst_folder}/train/round_0_client_2\", imgsz=512, batch=4, split='train')\n",
    "\n",
    "\n",
    "#=================================================================client_3====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c3.yaml\", project=f\"{dst_folder}/train/round_0_client_3\", imgsz=512, batch=4, split='train')\n",
    "\n",
    "\n",
    "#=================================================================client_4====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c4.yaml\", project=f\"{dst_folder}/train/round_0_client_4\", imgsz=512, batch=4, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5ad8f-f6a1-4185-ae7c-471b6f24bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_learning(initial_weights, client_no, participating_client, round_no, epochs, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c09eb1-9d72-4c31-a45e-35f157458602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dict to a serializable format\n",
    "def dict_to_serializable(d):\n",
    "    serializable_dict = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, (int, float, str, list, dict)):\n",
    "            serializable_dict[key] = value\n",
    "        else:\n",
    "            serializable_dict[key] = str(value)  # Convert non-serializable types to string\n",
    "    return serializable_dict\n",
    "\n",
    "# Save as JSON\n",
    "save_dir = dst_folder\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "file_path = os.path.join(save_dir, 'validation_dict.json')\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(dict_to_serializable(validation_dict), f, indent=4)\n",
    "\n",
    "print(f\"Validation dictionary saved to {file_path}\")\n",
    "\n",
    "\n",
    "file_path = os.path.join(save_dir, 'validation_dict.json')\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, 'r') as f:\n",
    "    loaded_dict = json.load(f)\n",
    "\n",
    "# Print the loaded dictionary\n",
    "print(\"Validation dictionary loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
