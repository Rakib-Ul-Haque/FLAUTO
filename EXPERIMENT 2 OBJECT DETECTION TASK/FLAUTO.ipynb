{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c426fe1-0637-4a46-aaa3-e442fae0f074",
   "metadata": {},
   "source": [
    "<h4>Paper title: Federated Learning with Automated Dual-Level Hyperparameter Tuning</h4>\n",
    "\n",
    "<h4>Authors: Rakib Ul Haque and Panagiotis (Panos P.) Markopoulos</h4>\n",
    "\n",
    "<h4>Affiliation: The University of Texas at San Antonio</h4>\n",
    "\n",
    "<h4>Emails: rakibul.haque@utsa.edu; panagiotis.markopoulos@utsa.edu</h4>\n",
    "\n",
    "<h4>Code by: rakibul.haque@utsa.edu</h4>\n",
    "\n",
    "<h4>Date: 01/09/2025</h4>\n",
    "\n",
    "<h4>Cite as: R. Ul Haque and P. Markopoulos, \"Federated Learning with Automated Dual-Level Hyperparameter Tuning\", 2025.</h4>\n",
    "\n",
    "<h4>Datasets and weights repository: https://utsacloud-my.sharepoint.com/:f:/g/personal/rakibul_haque_utsa_edu/Ei3tkowR-hlJnDHdIlMdAFsBnDrRqAclgFd0OZVJBytlWg?e=jt2cSt</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8977f2-2b93-4cb7-8ed2-c40bb76b2132",
   "metadata": {},
   "source": [
    "<h1><b>Libraries</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f2595-e9ae-445a-8ee6-9087897e42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import copy\n",
    "from collections import deque\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c00be3-0979-40e1-a120-989b8a3c643e",
   "metadata": {},
   "source": [
    "<h1><b>Measures</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58712144-4c00-46f1-88ae-ab81fcf00366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print function\n",
    "def Print(string, dictionary):\n",
    "    first_key = next(iter(dictionary))\n",
    "    first_value = dictionary[first_key]\n",
    "    print(f\"{string}:{first_key}: {first_value[0][0]}\\n\")\n",
    "\n",
    "# forbinus norm function\n",
    "def forbinus_norm_function(w_i):\n",
    "    value = 0\n",
    "    for k in w_i.keys():\n",
    "        value += torch.linalg.norm(w_i[k])\n",
    "    return value.item()\n",
    "\n",
    "# model deviation function\n",
    "def model_deviation_function(m1, m2):\n",
    "    \n",
    "    #model deviation code\n",
    "    w_i = {key: value.to(device) for key, value in m1.items()}\n",
    "    w_f = {key: value.to(device) for key, value in m2.items()}\n",
    "    \n",
    "    model_deviation = 0\n",
    "    for k in w_i.keys():\n",
    "        model_deviation += torch.linalg.norm(w_f[k].to(torch.float) - w_i[k].to(torch.float)) / (torch.linalg.norm(w_i[k].to(torch.float) +1) )\n",
    "    return model_deviation.item()\n",
    "\n",
    "\n",
    "# data path identification\n",
    "def on_train_epoch_end(trainer):\n",
    "    \"\"\"Custom logic for additional metrics logging at the end of each training epoch.\"\"\"\n",
    "    global path\n",
    "    path=trainer.csv\n",
    "\n",
    "# define function to add data from another DataFrame\n",
    "def add_data_to_client(client_id, new_data):\n",
    "    global clients\n",
    "    if client_id in clients:\n",
    "        # Append new data to the client's DataFrame\n",
    "        clients[client_id] = pd.concat([clients[client_id], new_data], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Client {client_id} does not exist.\")\n",
    "\n",
    "\n",
    "# deleting run folder for saving spaces\n",
    "def delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove the folder and all its contents\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' deleted successfully!\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fffbb0-f75b-4dbf-8e1f-c703b691c580",
   "metadata": {},
   "source": [
    "<h1><b>Train function</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02db6c3-c40e-4a3e-bd08-4544786295ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#averaging the weihgts\n",
    "\n",
    "def average_weights_function(dicts):\n",
    "    # Initialize an empty dictionary to store the summed weights\n",
    "    summed_weights = {}\n",
    "    \n",
    "    # Initialize an empty dictionary to keep track of how many times each key is seen\n",
    "    key_occurrences = {}\n",
    "    \n",
    "    # Iterate through all the dictionaries\n",
    "    for d in dicts:\n",
    "        for key, value in d.items():\n",
    "            if key in summed_weights:\n",
    "                summed_weights[key] += value\n",
    "                key_occurrences[key] += 1\n",
    "            else:\n",
    "                summed_weights[key] = value\n",
    "                key_occurrences[key] = 1\n",
    "    \n",
    "    # Create a dictionary to store the final averaged weights\n",
    "    averaged_weights = {}\n",
    "    \n",
    "    # Iterate through the summed weights and divide by the number of occurrences for each key\n",
    "    for key, value in summed_weights.items():\n",
    "        if key_occurrences[key] > 1:\n",
    "            averaged_weights[key] = value / key_occurrences[key]\n",
    "        else:\n",
    "            averaged_weights[key] = value  # If only present in one dict, keep as is\n",
    "    \n",
    "    return averaged_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074839c2-96f9-49cb-acc3-e9804ec0ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training( i_w, E, r, c, l_rate):\n",
    "\n",
    "    print(\"\\n\\n\\n=======current learning rate\", l_rate, \"====\\n\\n\\n\\n\")\n",
    "    #declear local model\n",
    "    global path, count_e, client_limit, min_b, max_b, opti\n",
    "    local_model=YOLO(\"initial_weights.pt\").to(device)\n",
    "    local_model.load_state_dict(i_w)\n",
    "    print(local_model.info())\n",
    "    total_val_loss=[]\n",
    "    total_train_loss=[]\n",
    "    c_limit=client_limit\n",
    "    batch_s=min_b\n",
    "\n",
    "    Step_Size_b=(max_b - batch_s) / (client_limit)\n",
    "    \n",
    "    rmd_pe=[]\n",
    "    #rmd_pe.append(0)\n",
    "    flag=0\n",
    "    le_rate=l_rate\n",
    "    #local_model.load_state_dict(i_w,strict=False)\n",
    "    checking_weights = local_model.state_dict()\n",
    "    Print(f\"Client {c} functions weights\", checking_weights)\n",
    "    \n",
    "    #epochs\n",
    "    for e in range(0,E):\n",
    "        count_e=count_e+1\n",
    "        local_model.add_callback(\"on_train_epoch_end\", on_train_epoch_end)\n",
    "        local_model.train(data=f\"{fl_a}/{set_up}/c{c}.yaml\", project=f\"{dst_folder}/train/round_{r}_client_{c}/{e}\", \n",
    "                          workers=0, epochs=1, imgsz=512, \n",
    "                          split='train', lr0=le_rate, batch=batch_s, optimizer=opti, \n",
    "                          val=True, device=0)\n",
    "        \n",
    "        fff_weights = {k: v.clone() for k, v in local_model.state_dict().items()}\n",
    "        \n",
    "        modev_pe=model_deviation_function(i_w,fff_weights)\n",
    "        rmd_pe.append(modev_pe)\n",
    "        \n",
    "        print(\"model deviation\", modev_pe)\n",
    "        \n",
    "        #collecting results\n",
    "        df = pd.read_csv(path)\n",
    "        #print(path)\n",
    "        #print(df)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        t_loss= df['train/box_loss'] + df['train/cls_loss'] + df['train/dfl_loss']\n",
    "        total_train_loss.append(t_loss.iloc[0])#print(df['train/box_loss'])\n",
    "        \n",
    "        v_loss= df['val/box_loss'] + df['val/cls_loss'] + df['val/dfl_loss']\n",
    "        total_val_loss.append(v_loss.iloc[0])#print(df['train/box_loss'])\n",
    "\n",
    "        if e>0:\n",
    "            rmd_change=abs(rmd_pe[e]-rmd_pe[e-1])/rmd_pe[e-1]\n",
    "            print(\"rmd_change\", rmd_change)\n",
    "            if( ((rmd_pe[e] <1) and (rmd_change*100) <20 ) or (total_train_loss[e] >= total_train_loss[e-1]) ):\n",
    "                c_limit=c_limit-1\n",
    "                if(c_limit<=0):\n",
    "                    break\n",
    "                batch_s= round(batch_s + Step_Size_b)\n",
    "                if batch_s >= max_b:\n",
    "                    batch_s = max_b\n",
    "    \n",
    "    #checking initial weights\n",
    "    Print(f\"Client {c} initial weights\", i_w)\n",
    "    #colleting final weights\n",
    "    client_final_weights = {k: v.clone() for k, v in local_model.state_dict().items()}#local_model.state_dict()\n",
    "    Print(f\"Client {c} final weights\",client_final_weights)    \n",
    "    #clear_output(wait=False)\n",
    "    #return client_final_weights, total_val_loss, v_loss.iloc[0]\n",
    "    return client_final_weights, v_loss.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98143e70-435d-4eca-a098-baca44aa5a15",
   "metadata": {},
   "source": [
    "<h1><b>FL structure</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9d5d8-d543-4805-b2f6-fa5e31935c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(i_w, C, P, R, E, b_size):\n",
    "\n",
    "    # declearning global validtion dictionary\n",
    "    global global_model, min_LR, max_LR, global_Step_Size_LR, server_limit\n",
    "    global validation_dict\n",
    "    global dst_folder\n",
    "    global device\n",
    "    \n",
    "    model_weights_queue = deque(maxlen=2)\n",
    "    \n",
    "    global_model.load_state_dict(i_w)\n",
    "    c_lr=min_LR\n",
    "    r_val_list=[]\n",
    "    r_val_list.append(0)\n",
    "    #global average_weights\n",
    "    #loop for round\n",
    "    for r in range(1,R+1):\n",
    "        models=[]\n",
    "        c_val_list=[]\n",
    "        #global_model = YOLO(f\"Fed_Avg/weights/round_{r-1}_weighs\").to(device)\n",
    "        i_w = {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "        Print(\"Model's initial weights\", i_w)\n",
    "        # averaged training weights per rounds\n",
    "        #average_weights = {}\n",
    "        #loop for clients\n",
    "        for c in range(1,C+1):\n",
    "\n",
    "            #training\n",
    "            clients_weight, val_loss=training(i_w, E, r, c, c_lr)\n",
    "            models.append(clients_weight)\n",
    "            c_val_list.append(val_loss)\n",
    "        \n",
    "        all_final_weights=average_weights_function(models)\n",
    "        r_val_list.append( sum(c_val_list)/len(c_val_list) )\n",
    "\n",
    "        model_weights_queue.append(all_final_weights)\n",
    "        \n",
    "        #torch.save(average_weights, f'{dst_folder}/weights/round_{r}_weighs.pt')\n",
    "        os.makedirs(os.path.join(dst_folder, \"weights\"), exist_ok=True)  # Creates both Fed_Avg and weights if needed\n",
    "        # Now you can save the weights as usual:\n",
    "        torch.save(all_final_weights, f'{dst_folder}/weights/after_round_{r}_weighs.pt')\n",
    "        \n",
    "        val_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "        val_model.load_state_dict(all_final_weights)\n",
    "        #global_model = load_model_weights_partial(\"yolov8n-obb.yaml\", average_weights, device)\n",
    "             \n",
    "        #chceking averaged weights\n",
    "        c_weight= {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "        Print(f\"updated global model after round {r}\",c_weight)\n",
    "        \n",
    "        #performing round validations\n",
    "        validation_results = val_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_{r}\", \n",
    "                                           imgsz=512, batch=4, split='val', device=0, workers=0)\n",
    "        \n",
    "        #save validation results into dict \n",
    "        validation_dict[f\"round_{r}\"] = validation_results\n",
    "\n",
    "        if r>1:\n",
    "            if server_limit > 0:\n",
    "                #round_LR_context.append( (iid_val_loss[i] > iid_val_loss[i-1]) and (min_LR > 0.0001) )\n",
    "                if (r_val_list[r] > r_val_list[r-1]) and (min_LR > 0.0001):\n",
    "                    max_LR=min_LR\n",
    "                    min_LR=round(min_LR - global_Step_Size_LR,4)\n",
    "                    min_LR=min_LR\n",
    "                    server_limit=server_limit-1\n",
    "                    global_Step_Size_LR = (max_LR - min_LR) / (2 ** server_limit)\n",
    "                    all_final_weights = model_weights_queue.popleft()\n",
    "                    model_weights_queue.clear()\n",
    "                    model_weights_queue.append(all_final_weights)\n",
    "                    #c_lr=min_LR\n",
    "                elif r_val_list[r] <= r_val_list[r-1]:\n",
    "                    min_LR=round(min_LR + global_Step_Size_LR,4)\n",
    "                    if min_LR>=max_LR:\n",
    "                        min_LR=max_LR\n",
    "                c_lr=min_LR\n",
    "                        \n",
    "        global_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "        global_model.load_state_dict(all_final_weights)\n",
    "\n",
    "        #chceking averaged weights\n",
    "        c_weight= {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "        Print(f\"updated global model after round {r}\",c_weight)\n",
    "        \n",
    "        #Print(\"updated global model\",i_w)\n",
    "        \n",
    "        print(\"round\", r, \"completed\")\n",
    "        # clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfa716-9624-4848-945f-40ab1f830280",
   "metadata": {},
   "source": [
    "<h1><b>Define Parameters</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582dd5f0-c9cc-4d2c-a75f-310dcfaae587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Parameters==============================================================\n",
    "round_no=30\n",
    "client_no=4\n",
    "participating_client=client_no\n",
    "# learning_rate=0.01\n",
    "batch_size=4\n",
    "epochs=5\n",
    "opti='Adam'\n",
    "count_e=0\n",
    "\n",
    "\n",
    "min_LR=0.0001\n",
    "min_b=4\n",
    "max_LR=0.09\n",
    "max_b=6\n",
    "\n",
    "\n",
    "client_limit=4 #4 is used to generate all the graphs \n",
    "server_limit=4 #4 is sued to generate al the graphs\n",
    "\n",
    "\n",
    "global_Step_Size_LR = (max_LR - min_LR) / (( 2 ** server_limit))\n",
    "\n",
    "#===========other variables=============================================\n",
    "validation_dict = {}\n",
    "# Define the destination folder\n",
    "fl_a=\"hFL\"\n",
    "\n",
    "set_up=\"limited_data\"\n",
    "forname=set_up\n",
    "\n",
    "dst_folder = f\"{fl_a}_{forname}_Fed_AutoHT_{opti}\"\n",
    "# dst_folder = f\"Fed_Avg\"\n",
    "delete_folder(dst_folder)\n",
    "\n",
    "\n",
    "path=\"\"\n",
    "\n",
    "#client results storage\n",
    "clients = {f'client_{i}': pd.DataFrame(columns=['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\n",
    "       'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)',\n",
    "       'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',\n",
    "       'lr/pg0', 'lr/pg1', 'lr/pg2']) for i in range(1,10)}\n",
    "\n",
    "#===================================loading the saved weight list====================================================\n",
    "global_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "global_model.info()\n",
    "initial_weights = {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "print(len(initial_weights))\n",
    "Print(\"Model's initial weights\", initial_weights)\n",
    "# global_model.save('current.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6150f-c6eb-494f-bd54-4ae1ccf8c41c",
   "metadata": {},
   "source": [
    "<h1><b>Round 0</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e5fcc0-fc0d-448b-bf71-9cd723ab30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "#server validation rounds\n",
    "validation_results = l_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_0\", imgsz=512, batch=4,split='val', device=0,workers=0)\n",
    "validation_dict[\"round_0\"] = validation_results\n",
    "print(validation_results)\n",
    "\n",
    "#=================================================================client_1====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c1.yaml\", project=f\"{dst_folder}/train/round_0_client_1\", imgsz=512, batch=4, split='train', device=0, workers=0)\n",
    "\n",
    "#=================================================================client_2====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c2.yaml\", project=f\"{dst_folder}/train/round_0_client_2\", imgsz=512, batch=4, split='train', device=0, workers=0)\n",
    "\n",
    "\n",
    "#=================================================================client_3====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c3.yaml\", project=f\"{dst_folder}/train/round_0_client_3\", imgsz=512, batch=4, split='train',device=0, workers=0)\n",
    "\n",
    "\n",
    "#=================================================================client_4====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c4.yaml\", project=f\"{dst_folder}/train/round_0_client_4\", imgsz=512, batch=4, split='train', device=0, workers=0)\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abacd373-fecb-4c0e-a112-a37c649ac492",
   "metadata": {},
   "source": [
    "<h1><b>Run FL</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a04c08-997f-4641-afc9-553610909c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "federated_learning(initial_weights, client_no, participating_client, round_no, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c2b62e-a250-4440-8d15-6cefba754764",
   "metadata": {},
   "source": [
    "<h1><b>Save the validation dict</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ce2c8-04cd-4e64-9caf-a4c517059d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dict to a serializable format\n",
    "def dict_to_serializable(d):\n",
    "    serializable_dict = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, (int, float, str, list, dict)):\n",
    "            serializable_dict[key] = value\n",
    "        else:\n",
    "            serializable_dict[key] = str(value)  # Convert non-serializable types to string\n",
    "    return serializable_dict\n",
    "\n",
    "# Save as JSON\n",
    "save_dir = dst_folder\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "file_path = os.path.join(save_dir, 'validation_dict.json')\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(dict_to_serializable(validation_dict), f, indent=4)\n",
    "\n",
    "print(f\"Validation dictionary saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65acbf50-7cb6-4f0b-af1f-c42481d74da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(save_dir, 'validation_dict.json')\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, 'r') as f:\n",
    "    loaded_dict = json.load(f)\n",
    "\n",
    "# Print the loaded dictionary\n",
    "print(\"Validation dictionary loaded successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
