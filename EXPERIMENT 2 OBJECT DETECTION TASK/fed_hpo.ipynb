{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba047f9d-1ed0-4990-9252-93f340cc1067",
   "metadata": {},
   "source": [
    "<h4> This code is part of FLAUTO. It implements FedHPO. Date: 01/09/2025 </h4>\n",
    "<h4> Contact: rakibul.haque@utsa.edu </h4>  \n",
    "<h4> Cite as: R. U. Haque and P. Markopoulos,\"Federated Learning with Automated Dual-Level Hyperparameter Tuning\", 2025 <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8cbc79-5902-4b14-9542-141d48dea829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def Print(string, dictionary):\n",
    "    first_key = next(iter(dictionary))\n",
    "    first_value = dictionary[first_key]\n",
    "    print(f\"{string}:{first_key}: {first_value[0][0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267adfb3-238d-461c-bdc9-55c809128f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_train_epoch_end(trainer):\n",
    "    \"\"\"Custom logic for additional metrics logging at the end of each training epoch.\"\"\"\n",
    "    global path\n",
    "    path=trainer.csv\n",
    "\n",
    "# define function to add data from another DataFrame\n",
    "def add_data_to_client(client_id, new_data):\n",
    "    global clients\n",
    "    if client_id in clients:\n",
    "        # Append new data to the client's DataFrame\n",
    "        clients[client_id] = pd.concat([clients[client_id], new_data], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Client {client_id} does not exist.\")\n",
    "\n",
    "# deleting run folder for saving spaces\n",
    "def delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove the folder and all its contents\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' deleted successfully!\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")\n",
    "\n",
    "def average_weights_function(dicts):\n",
    "    # Initialize an empty dictionary to store the summed weights\n",
    "    summed_weights = {}\n",
    "\n",
    "    # Initialize an empty dictionary to keep track of how many times each key is seen\n",
    "    key_occurrences = {}\n",
    "\n",
    "    # Iterate through all the dictionaries\n",
    "    for d in dicts:\n",
    "        for key, value in d.items():\n",
    "            if key in summed_weights:\n",
    "                summed_weights[key] += value\n",
    "                key_occurrences[key] += 1\n",
    "            else:\n",
    "                summed_weights[key] = value\n",
    "                key_occurrences[key] = 1\n",
    "\n",
    "    # Create a dictionary to store the final averaged weights\n",
    "    averaged_weights = {}\n",
    "\n",
    "    # Iterate through the summed weights and divide by the number of occurrences for each key\n",
    "    for key, value in summed_weights.items():\n",
    "        if key_occurrences[key] > 1:\n",
    "            averaged_weights[key] = value / key_occurrences[key]\n",
    "        else:\n",
    "            averaged_weights[key] = value  # If only present in one dict, keep as is\n",
    "\n",
    "    return averaged_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf420db-fb9b-4319-8f80-08989ef0cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training( i_w, E, r, c, l_rate):\n",
    "    #declear local model\n",
    "    global path, count_e\n",
    "    local_model=YOLO(\"initial_weights.pt\").to(device)\n",
    "    local_model.load_state_dict(i_w)\n",
    "    print(local_model.info())\n",
    "    total_loss=[]\n",
    "    flag=0\n",
    "    le_rate=l_rate\n",
    "    #local_model.load_state_dict(i_w,strict=False)\n",
    "    checking_weights = local_model.state_dict()\n",
    "    Print(f\"Client {c} functions weights\", checking_weights)\n",
    "\n",
    "    #epochs\n",
    "    for e in range(0,E):\n",
    "        count_e=count_e+1\n",
    "        local_model.add_callback(\"on_train_epoch_end\", on_train_epoch_end)\n",
    "        local_model.train(data=f\"{fl_a}/{set_up}/c{c}.yaml\", project=f\"{dst_folder}/train/round_{r}_client_{c}/{e}\", workers=0, epochs=1, imgsz=512, split='train', lr0=le_rate, batch=4, optimizer=opti, val=True, device=0, warmup_epochs=0)\n",
    "\n",
    "        #collecting results\n",
    "        df = pd.read_csv(path)\n",
    "        #print(path)\n",
    "        #print(df)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        t_loss= df['val/box_loss'] + df['val/cls_loss'] + df['val/dfl_loss']\n",
    "        total_loss.append(t_loss.iloc[0])#print(df['train/box_loss'])\n",
    "\n",
    "        if e>0:\n",
    "            print(abs(total_loss[e] - total_loss[e-1]))\n",
    "            if abs(total_loss[e] - total_loss[e-1]) < 0.5:\n",
    "                le_rate= le_rate * 0.5\n",
    "                print(f\"updated Lr {le_rate}\")\n",
    "\n",
    "                flag=flag+1\n",
    "                if flag>=3:\n",
    "                    break\n",
    "\n",
    "        #add_data_to_client(f'client_{c}', df)\n",
    "\n",
    "    #checking initial weights\n",
    "    Print(f\"Client {c} initial weights\", i_w)\n",
    "    #colleting final weights\n",
    "    client_final_weights = {k: v.clone() for k, v in local_model.state_dict().items()}#local_model.state_dict()\n",
    "    Print(f\"Client {c} final weights\",client_final_weights)\n",
    "    #clear_output(wait=False)\n",
    "\n",
    "    # Move weights to the same device\n",
    "    for key in i_w.keys():\n",
    "        i_w[key] = i_w[key].to(device)\n",
    "        client_final_weights[key] = client_final_weights[key].to(device)\n",
    "\n",
    "    model_update = {}\n",
    "    for key in i_w.keys():\n",
    "        model_update[key] = torch.sub(i_w[key], client_final_weights[key])\n",
    "\n",
    "    return model_update\n",
    "\n",
    "\n",
    "def average_updates(w, n_k):\n",
    "    w_avg = deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        w_avg[key] = torch.mul(w_avg[key], n_k[0])\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] = torch.add(w_avg[key], w[i][key], alpha=n_k[i])\n",
    "        w_avg[key] = torch.div(w_avg[key], sum(n_k))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07159770-4616-48b3-80d9-90a1096dc8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(i_w, C, P, R, E, learning_rate, b_size):\n",
    "\n",
    "    # declearning global validtion dictionary\n",
    "    global global_model, data_size, v\n",
    "    global validation_dict\n",
    "    global dst_folder\n",
    "    global device\n",
    "    global_model.load_state_dict(i_w)\n",
    "    \n",
    "    #loop for round\n",
    "    for r in range(1,R+1):\n",
    "\n",
    "        models=[]\n",
    "        average_weights={}\n",
    "        #global_model = YOLO(f\"Fed_Avg/weights/round_{r-1}_weighs\").to(device)\n",
    "        i_w = {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "        Print(\"Model's initial weights\", i_w)\n",
    "        #loop for clients\n",
    "        for c in range(1,C+1):\n",
    "\n",
    "            #training\n",
    "            model_update = training(i_w, E, r, c, learning_rate)\n",
    "            models.append(model_update)\n",
    "\n",
    "\n",
    "        # average_weights=average_weights_function(models)\n",
    "        update_avg = average_updates( models, data_size)\n",
    "\n",
    "        if v is None:\n",
    "            v = deepcopy(update_avg)\n",
    "        else:\n",
    "            for key in v.keys():\n",
    "                v[key] = update_avg[key] + (v[key] * 0.99)\n",
    "                \n",
    "        for key in i_w:\n",
    "            average_weights[key]=i_w[key] - (v[key] * 1)\n",
    "            \n",
    "        #torch.save(average_weights, f'{dst_folder}/weights/round_{r}_weighs.pt')\n",
    "        os.makedirs(os.path.join(dst_folder, \"weights\"), exist_ok=True)  # Creates both Fed_Avg and weights if needed\n",
    "\n",
    "        global_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "        global_model.load_state_dict(average_weights)\n",
    "        torch.save(global_model, f'{dst_folder}/weights/after_round_{r}_weighs.pt')\n",
    "\n",
    "        val_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "        val_model.load_state_dict(average_weights)\n",
    "        #global_model = load_model_weights_partial(\"yolov8n-obb.yaml\", average_weights, device)\n",
    "\n",
    "        #chceking averaged weights\n",
    "        c_weight= {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "        Print(f\"updated global model after round {r}\",c_weight)\n",
    "\n",
    "        #performing round validations\n",
    "        validation_results = val_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_{r}\", imgsz=512, batch=4, split='val', device=0, workers=0)\n",
    "        #save validation results into dict\n",
    "        validation_dict[f\"round_{r}\"] = validation_results\n",
    "\n",
    "        #Print(\"updated global model\",i_w)\n",
    "\n",
    "        print(\"round\", r, \"completed\")\n",
    "        # clear_output(wait=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef619a-06ea-4350-8f30-b90bc0ec4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Parameters==============================================================\n",
    "round_no=30\n",
    "client_no=4\n",
    "participating_client=client_no\n",
    "learning_rate=0.01\n",
    "batch_size=4\n",
    "epochs=5\n",
    "opti='SGD'\n",
    "count_e=0\n",
    "data_size=[]\n",
    "v=None\n",
    "\n",
    "#===========other variables=============================================\n",
    "validation_dict = {}\n",
    "# Define the destination folder\n",
    "\n",
    "# ===========================================FL type\n",
    "fl_a=\"hFL\"\n",
    "\n",
    "# ===========================================FL data setup applicable for cleint 4\n",
    "set_up=\"IID\"\n",
    "# set_up=\"limited_data\"\n",
    "\n",
    "if set_up=='IID':\n",
    "    data_size.append(70)\n",
    "    data_size.append(70)\n",
    "    data_size.append(70)\n",
    "    data_size.append(70)\n",
    "else: \n",
    "    data_size.append(70)\n",
    "    data_size.append(70)\n",
    "    data_size.append(70)\n",
    "    data_size.append(30)\n",
    "\n",
    "forname=set_up\n",
    "\n",
    "dst_folder = f\"{fl_a}_{forname}_Fed_Hpo_{learning_rate}_{opti}\"\n",
    "# dst_folder = f\"Fed_Avg\"\n",
    "delete_folder(dst_folder)\n",
    "\n",
    "path=\"\"\n",
    "\n",
    "#client results storage\n",
    "clients = {f'client_{i}': pd.DataFrame(columns=['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\n",
    "       'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)',\n",
    "       'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',\n",
    "       'lr/pg0', 'lr/pg1', 'lr/pg2']) for i in range(1,10)}\n",
    "\n",
    "#===================================loading the saved weight list====================================================\n",
    "global_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "global_model.info()\n",
    "initial_weights = {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "print(len(initial_weights))\n",
    "Print(\"Model's initial weights\", initial_weights)\n",
    "# global_model.save('current.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ec545-44f6-4dff-b2e7-fa84e9cd90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "#server validation rounds\n",
    "validation_results = l_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_0\", imgsz=512, batch=4,split='val', device=0, workers=0)\n",
    "validation_dict[\"round_0\"] = validation_results\n",
    "print(validation_results)\n",
    "\n",
    "#=================================================================client_1====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c1.yaml\", project=f\"{dst_folder}/train/round_0_client_1\", imgsz=512, batch=4, split='train', device=0, workers=0)\n",
    "\n",
    "#=================================================================client_2====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c2.yaml\", project=f\"{dst_folder}/train/round_0_client_2\", imgsz=512, batch=4, split='train', device=0, workers=0)\n",
    "\n",
    "\n",
    "#=================================================================client_3====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c3.yaml\", project=f\"{dst_folder}/train/round_0_client_3\", imgsz=512, batch=4, split='train',device=0, workers=0)\n",
    "\n",
    "\n",
    "#=================================================================client_4====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c4.yaml\", project=f\"{dst_folder}/train/round_0_client_4\", imgsz=512, batch=4, split='train', device=0, workers=0)\n",
    "# clear_output(wait=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbf1ee-4c89-48b1-939f-9bac13c5fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters 3,085,440 parameters, 3,085,424 gradients\n",
    "federated_learning(initial_weights, client_no, participating_client, round_no, epochs, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa1f90-1661-4460-8869-85a86f43675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"global epoch\", count_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7e558-d943-49bb-bf8e-8fd87559499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dict to a serializable format\n",
    "def dict_to_serializable(d):\n",
    "    serializable_dict = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, (int, float, str, list, dict)):\n",
    "            serializable_dict[key] = value\n",
    "        else:\n",
    "            serializable_dict[key] = str(value)  # Convert non-serializable types to string\n",
    "    return serializable_dict\n",
    "\n",
    "# Save as JSON\n",
    "save_dir = dst_folder\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "file_path = os.path.join(save_dir, f\"validation_dict_{count_e}.json\")\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(dict_to_serializable(validation_dict), f, indent=4)\n",
    "\n",
    "print(f\"Validation dictionary saved to {file_path}\")\n",
    "\n",
    "\n",
    "file_path = os.path.join(save_dir, f\"validation_dict_{count_e}.json\")\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, 'r') as f:\n",
    "    loaded_dict = json.load(f)\n",
    "\n",
    "# Print the loaded dictionary\n",
    "print(\"Validation dictionary loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
